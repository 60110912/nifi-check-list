- DBCPConnectionPool и другие ControllerServices вложены в ProcessGroup Не должно быть подключений в нутри процессоров.
- Все параметры изменяемые при смене окружений должны быть заданы через variables/parameters (например имя сервера, порт, имя бд, bootstrap сервера кафки, топики, консюмер группы, пользователь кафки и т.д)
Про 3: Put sql, S3, kafka.
- Не должно быть выключенных или остановленных процессоров и соответственно очередей которые ведут к ним и переполнятся
включенны через enable.
- Скрипты должны быть выложены на диск всех нод nifi и поставляться через отдельный репозиторий
Про скрип тип.
- Ко всем процессорам требуется в начале указать префикс системы, для сбора метрик
Процессоры должны называться единотипно, а именно начинаться одинаково.

ConsumeKafkaRecord должен иметь выход parse failure выходящий на дополнительный ConvertRecord, поскольку при потери сети до SchemaRegistry теряются сообщения
Это проверка на failure

Запуск процедуры raw_to_ods должен производится через airflow не проверяем.


Файлы который считываются с диска должны читаться из директории /etc/nifi/current/ например библиотеки: /etc/nifi/current/lib/  скрипты: /etc/nifi/current/scripts/js полное содержимое можно посмотреть в artefactory в последнем релизе:
Ситуационно.

Merge перед вставкой в GP должен иметь параметры Minimum Number of Entries не меньше 5000 и Max Bin Age не меньше 300 sec
PutSQL 1.11.4  не интересует в Gp или не в GP.
Put S3
Еще могут быть параметры и переменные.

Все SSL сервисы как trustore должны использовать /etc/nifi/current/adeo_empty_pass.jks в котором используется пустой пароль, в это хранилище нужно добавлять свои сертификаты относящиеся к корневым сертификатам adeo. Дополнять можно с помощью программы KeyStore Explorer
Вроде правильно


org.apache.nifi.processors.aws.s3.PutS3Object


Параметр начинаться с #